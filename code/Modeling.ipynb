{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "\n",
    "\n",
    "- https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory\n",
    "- https://stackoverflow.com/questions/19377969/combine-two-columns-of-text-in-dataframe-in-pandas-python\n",
    "- https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import regex as re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "from pandas.io import sql\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to scrub a text string\n",
    "def scrub_text(in_text):\n",
    "    # Instantiate lemmatizer\n",
    "    lemma = WordNetLemmatizer()\n",
    "    # Expanded stop words\n",
    "    ext_stop = stopwords.words('english')\n",
    "    ext_stop.extend(['im','ive','dont','hes','got'])\n",
    "    # Remove punctuation and lower case words\n",
    "    word_list = re.sub(r'[^a-zA-Z ]','',in_text.lower()).split()\n",
    "#    word_list = [lemma.lemmatize(i) for i in word_list]\n",
    "    word_list = [i for i in word_list if i not in ext_stop]\n",
    "    return ' '.join(word_list)\n",
    "\n",
    "\n",
    "# Read in data from SQL database\n",
    "def read_from_database(SQL, engine = None):\n",
    "    # write posts to the posts table\n",
    "    if engine == None:\n",
    "        return\n",
    "    return pd.read_sql(SQL, con = engine)\n",
    "\n",
    "\n",
    "# Clean text columns\n",
    "def clean_columns(df, features = [], subset = None):\n",
    "    # For each feature in column scrub the text\n",
    "    # and create a new column with the cleaned data\n",
    "    for feature in features:\n",
    "        try:\n",
    "            df[feature] = df[feature].apply(scrub_text)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # drop the duplicates using the subset column as the key\n",
    "    df.drop_duplicates(subset = subset, inplace=True)\n",
    "    \n",
    "\n",
    "# Read data from database and output model-ready dataframe\n",
    "def create_model_df(engine = None, y = 'subreddit', X_columns = [], subset = None,\n",
    "                    subreddit_1 = None, subreddit_2 = None):\n",
    "    \n",
    "    # Build the SQL\n",
    "    SQL =  \"SELECT \" + y + \", \" + \", \".join(X_columns) + \" FROM posts WHERE \"\n",
    "    SQL = SQL + y + \" = \\'\" + str(subreddit_1) + \"\\'\" + \" OR \" + y + \" = \\'\" + str(subreddit_2) + \"\\'\"\n",
    "    \n",
    "    # Read this data from the database\n",
    "    df = read_from_database(SQL, engine = engine)\n",
    "    \n",
    "    # Clean the columns and drop duplicates\n",
    "    clean_columns(df, features = X_columns, subset = subset)\n",
    "    \n",
    "    # Merge the X_columns into a single text column\n",
    "    df[\"_\".join(X_columns)] = df[X_columns].apply(lambda x: ' '.join(x), axis = 1)\n",
    "        \n",
    "    df.drop(columns = X_columns, inplace = True)\n",
    "    \n",
    "    # Binarize the surreddit variables\n",
    "    df[y] = df[y].map({subreddit_1: 1, subreddit_2: 0})\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Classification models\n",
    "def class_model(df, x_col = None, y_col = None, vectorizer = 'cvec', model = 'bayem',\n",
    "                random_state = 42):\n",
    "    # Assign X and y variables\n",
    "    X = df[x_col]\n",
    "    y = df[y_col]\n",
    "    \n",
    "    # Train test split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state = random_state)\n",
    "    \n",
    "    # Set up the Pipeline\n",
    "    if vectorizer == 'cvec' and model == 'logistic':\n",
    "        pipe = Pipeline([('vec', CountVectorizer()),\n",
    "                         ('mod', LogisticRegression())\n",
    "                        ])\n",
    "    elif vectorizer == 'tfidf' and model == 'logistic':\n",
    "        pipe = Pipeline([('vec', TfidfVectorizer()),\n",
    "                         ('mod', LogisticRegression())\n",
    "                        ])\n",
    "    elif vectorizer == 'cvec' and model == 'bayem': \n",
    "        pipe = Pipeline([('vec', CountVectorizer()),\n",
    "                         ('mod', MultinomialNB())\n",
    "                        ])\n",
    "    elif vectorizer == 'tfidf' and model == 'bayem':\n",
    "        pipe = Pipeline([('vec', TfidfVectorizer()),\n",
    "                         ('mod', MultinomialNB())\n",
    "                        ])\n",
    "\n",
    "#     pipe_params = {'vec__stop_words': ['english'],\n",
    "#                     'vec__max_features': [None, 500, 1000],\n",
    "#                     'vec__min_df': [0.0],\n",
    "#                     'vec__max_df': [1.0],\n",
    "#                     'vec__ngram_range': [(1,1), (1,2)]\n",
    "#                     }\n",
    "    pipe_params = {'vec__max_features': [None, 500, 1000],\n",
    "                    'vec__min_df': [0.0],\n",
    "                    'vec__max_df': [1.0],\n",
    "                    'vec__ngram_range': [(1,1), (1,2)]\n",
    "                    }\n",
    "      \n",
    "    \n",
    "    # Set up the grid search\n",
    "    mod_out = {}\n",
    "    gs = GridSearchCV(estimator = pipe, param_grid = pipe_params, cv = 3)\n",
    "    gs.fit(X_train, y_train)\n",
    "    mod_out['train_score'] = gs.score(X_train, y_train)\n",
    "    mod_out['test_score'] = gs.score(X_test, y_test)\n",
    "    mod_out['y_test'] = y_test\n",
    "    mod_out['y_train'] = y_train\n",
    "    mod_out['y'] = y\n",
    "    mod_out['pred'] = gs.predict(X_test)\n",
    "    mod_out['proba'] = gs.predict_proba(X_test)\n",
    "    mod_out['best_param'] = gs.best_params_\n",
    "    mod_out['vocabulary'] = gs.best_estimator_.named_steps['vec'].vocabulary_\n",
    "    mod_out['features'] = gs.best_estimator_.named_steps['vec'].get_feature_names()\n",
    "    mod_out['vector_matrix'] = gs.best_estimator_.named_steps['vec'].transform(X)\n",
    "    \n",
    "    return mod_out\n",
    "\n",
    "\n",
    "# Read data from database and output model-ready dataframe\n",
    "def data_overview(engine = None, y = 'subreddit', X_columns = [], subset = None,\n",
    "                    subreddit_1 = None, subreddit_2 = None):\n",
    "    \n",
    "    # Build the SQL\n",
    "    SQL =  \"SELECT * FROM posts \" \n",
    "    \n",
    "    # Read this data from the database\n",
    "    df = read_from_database(SQL, engine = engine)\n",
    "    \n",
    "    for col in X_columns\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database engine\n",
    "engine = create_engine('postgres://postgres:pass@34.222.13.94:5432')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>comments</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>num_comments_cap</th>\n",
       "      <th>permalink</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t2_3l4ha</td>\n",
       "      <td>My fiancé and I just found out we’re having a ...</td>\n",
       "      <td>1.553870e+09</td>\n",
       "      <td>b6y1o8</td>\n",
       "      <td>t3_b6y1o8</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>/r/relationships/comments/b6y1o8/its_love_fest...</td>\n",
       "      <td>Time to share your happy stories with us. We r...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>It's Love Fest Friday!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t2_3i9a63ve</td>\n",
       "      <td>honestly, i thought this was going somewhere c...</td>\n",
       "      <td>1.553923e+09</td>\n",
       "      <td>b77few</td>\n",
       "      <td>t3_b77few</td>\n",
       "      <td>60</td>\n",
       "      <td>39</td>\n",
       "      <td>/r/relationships/comments/b77few/me_20m_with_m...</td>\n",
       "      <td>So this is gonna be weird all around because t...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>Me [20M] with my father [40M] who I met months...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t2_37ml46ds</td>\n",
       "      <td>&amp;gt;He also went overdrawn because of this and...</td>\n",
       "      <td>1.553891e+09</td>\n",
       "      <td>b7273a</td>\n",
       "      <td>t3_b7273a</td>\n",
       "      <td>101</td>\n",
       "      <td>59</td>\n",
       "      <td>/r/relationships/comments/b7273a/update_bf_31m...</td>\n",
       "      <td>UPDATE from previous post, original link here:...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>UPDATE: bf (31m) still using webcam girls desp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t2_tdy0zf1</td>\n",
       "      <td>Break up. This does not get better. His behavi...</td>\n",
       "      <td>1.553914e+09</td>\n",
       "      <td>b769id</td>\n",
       "      <td>t3_b769id</td>\n",
       "      <td>69</td>\n",
       "      <td>49</td>\n",
       "      <td>/r/relationships/comments/b769id/boyfriend_21m...</td>\n",
       "      <td>throwaway because he knows my reddit account, ...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>Boyfriend [21M] is constantly stalking me [20F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t2_1m5pvmux</td>\n",
       "      <td>Honestly, you won’t be enough for her until yo...</td>\n",
       "      <td>1.553924e+09</td>\n",
       "      <td>b77mho</td>\n",
       "      <td>t3_b77mho</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>/r/relationships/comments/b77mho/i_25m_have_an...</td>\n",
       "      <td>I get the \"then that means she isnt right for ...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>I (25M) have an inferiority complex and cannot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  author_fullname                                           comments  \\\n",
       "0        t2_3l4ha  My fiancé and I just found out we’re having a ...   \n",
       "1     t2_3i9a63ve  honestly, i thought this was going somewhere c...   \n",
       "2     t2_37ml46ds  &gt;He also went overdrawn because of this and...   \n",
       "3      t2_tdy0zf1  Break up. This does not get better. His behavi...   \n",
       "4     t2_1m5pvmux  Honestly, you won’t be enough for her until yo...   \n",
       "\n",
       "    created_utc      id       name  num_comments  num_comments_cap  \\\n",
       "0  1.553870e+09  b6y1o8  t3_b6y1o8            29                22   \n",
       "1  1.553923e+09  b77few  t3_b77few            60                39   \n",
       "2  1.553891e+09  b7273a  t3_b7273a           101                59   \n",
       "3  1.553914e+09  b769id  t3_b769id            69                49   \n",
       "4  1.553924e+09  b77mho  t3_b77mho            18                15   \n",
       "\n",
       "                                           permalink  \\\n",
       "0  /r/relationships/comments/b6y1o8/its_love_fest...   \n",
       "1  /r/relationships/comments/b77few/me_20m_with_m...   \n",
       "2  /r/relationships/comments/b7273a/update_bf_31m...   \n",
       "3  /r/relationships/comments/b769id/boyfriend_21m...   \n",
       "4  /r/relationships/comments/b77mho/i_25m_have_an...   \n",
       "\n",
       "                                            selftext      subreddit  \\\n",
       "0  Time to share your happy stories with us. We r...  relationships   \n",
       "1  So this is gonna be weird all around because t...  relationships   \n",
       "2  UPDATE from previous post, original link here:...  relationships   \n",
       "3  throwaway because he knows my reddit account, ...  relationships   \n",
       "4  I get the \"then that means she isnt right for ...  relationships   \n",
       "\n",
       "                                               title  \n",
       "0                             It's Love Fest Friday!  \n",
       "1  Me [20M] with my father [40M] who I met months...  \n",
       "2  UPDATE: bf (31m) still using webcam girls desp...  \n",
       "3  Boyfriend [21M] is constantly stalking me [20F...  \n",
       "4  I (25M) have an inferiority complex and cannot...  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the SQL\n",
    "SQL =  \"SELECT * FROM posts \" \n",
    "    \n",
    "# Read this data from the database\n",
    "df_a = read_from_database(SQL, engine = engine)\n",
    "df_a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.76923076923077"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sub_groups = ['relationships', 'diy','politics', 'woodworking']\n",
    "\n",
    "df_a['word_count'] = df_a['selftext'].apply(lambda x: len(x.split()))\n",
    "df_a['char_count'] = df_a['selftext'].apply(lambda x: len(x))\n",
    "\n",
    "avgs = df_a.groupby('subreddit').mean().unstack()\n",
    "avgs['word_count']['DIY']\n",
    "\n",
    "# fig, ax = plt.subplots(figsize = (20,10))\n",
    "# df_a[df_a['subreddit']=='relationships']\n",
    "# for sub in sub_groups:\n",
    "#     sns.distplot(df_a[df_a['subreddit']==sub]['word_count'], ax = ax, kde=False)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data from the database, clean data and binarize the reddit column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the modeling data\n",
    "# X_columns = ['title', 'selftext', 'comments']\n",
    "# subreddit_1 = 'relationships', subreddit_2 = 'DIY'\n",
    "# sub_groups = ['relationships', 'diy','politics', 'woodworking']\n",
    "\n",
    "df = create_model_df(engine = engine, y = 'subreddit', X_columns = ['title', 'selftext'], \n",
    "                subset = ['selftext'], subreddit_1 = 'woodworking', subreddit_2 = 'DIY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.56621\n",
       "0    0.43379\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the dependent variable\n",
    "df.subreddit.value_counts(normalize = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title_selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>temporarily disable demolished shed electrics ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>refinished free table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>sharkbite fittings restrict water pressure ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>general feedbackgetting started questions answ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>polyurethane scratching refinished table seale...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit                                     title_selftext\n",
       "0          0  temporarily disable demolished shed electrics ...\n",
       "1          0                             refinished free table \n",
       "2          0  sharkbite fittings restrict water pressure ins...\n",
       "3          0  general feedbackgetting started questions answ...\n",
       "8          0  polyurethane scratching refinished table seale..."
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classification model with these parameters\n",
    "m1 = class_model(df, x_col = 'title_selftext', y_col = 'subreddit', vectorizer = 'cvec', \n",
    "            model = 'bayem', random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score  1.0\n",
      "test score  0.8363636363636363\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>subreddit_class</th>\n",
       "      <th>DIY</th>\n",
       "      <th>woodworking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>0.449664</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>0.657718</td>\n",
       "      <td>0.595238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wood</th>\n",
       "      <td>0.456376</td>\n",
       "      <td>0.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>table</th>\n",
       "      <td>0.322148</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>0.328859</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>0.006711</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>need</th>\n",
       "      <td>0.315436</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>advice</th>\n",
       "      <td>0.187919</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>0.208054</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>find</th>\n",
       "      <td>0.067114</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>0.322148</td>\n",
       "      <td>0.261905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glass</th>\n",
       "      <td>0.040268</td>\n",
       "      <td>0.261905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>problem</th>\n",
       "      <td>0.093960</td>\n",
       "      <td>0.261905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>0.228188</td>\n",
       "      <td>0.261905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>help</th>\n",
       "      <td>0.308725</td>\n",
       "      <td>0.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>looking</th>\n",
       "      <td>0.255034</td>\n",
       "      <td>0.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want</th>\n",
       "      <td>0.261745</td>\n",
       "      <td>0.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>0.255034</td>\n",
       "      <td>0.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>router</th>\n",
       "      <td>0.060403</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>using</th>\n",
       "      <td>0.214765</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>back</th>\n",
       "      <td>0.127517</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concrete</th>\n",
       "      <td>0.100671</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anyone</th>\n",
       "      <td>0.127517</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>0.228188</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>something</th>\n",
       "      <td>0.174497</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finish</th>\n",
       "      <td>0.174497</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>0.302013</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cut</th>\n",
       "      <td>0.087248</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>door</th>\n",
       "      <td>0.187919</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>switch</th>\n",
       "      <td>0.046980</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guest following</th>\n",
       "      <td>0.006711</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guides week</th>\n",
       "      <td>0.006711</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guest bath</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guest</th>\n",
       "      <td>0.006711</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guessing use</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guessing questioning</th>\n",
       "      <td>0.006711</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guessing need</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guessing answer</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guessing</th>\n",
       "      <td>0.013423</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guides</th>\n",
       "      <td>0.006711</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guitar</th>\n",
       "      <td>0.006711</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guy told</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gutters</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guy homedepot</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guy added</th>\n",
       "      <td>0.006711</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guy</th>\n",
       "      <td>0.020134</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gutters worked</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gutters two</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gutters roof</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gutters make</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gurus built</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guitar neck</th>\n",
       "      <td>0.006711</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gurus</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guns beautiful</th>\n",
       "      <td>0.006711</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guns</th>\n",
       "      <td>0.006711</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gun want</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gun standard</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gun cleaner</th>\n",
       "      <td>0.006711</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gun</th>\n",
       "      <td>0.013423</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoom power</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22178 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "subreddit_class            DIY  woodworking\n",
       "like                  0.449664     0.666667\n",
       "would                 0.657718     0.595238\n",
       "wood                  0.456376     0.523810\n",
       "table                 0.322148     0.500000\n",
       "get                   0.328859     0.357143\n",
       "film                  0.006711     0.357143\n",
       "need                  0.315436     0.333333\n",
       "advice                0.187919     0.285714\n",
       "good                  0.208054     0.285714\n",
       "find                  0.067114     0.285714\n",
       "use                   0.322148     0.261905\n",
       "glass                 0.040268     0.261905\n",
       "problem               0.093960     0.261905\n",
       "way                   0.228188     0.261905\n",
       "help                  0.308725     0.238095\n",
       "looking               0.255034     0.238095\n",
       "want                  0.261745     0.238095\n",
       "make                  0.255034     0.238095\n",
       "router                0.060403     0.214286\n",
       "using                 0.214765     0.214286\n",
       "back                  0.127517     0.214286\n",
       "concrete              0.100671     0.214286\n",
       "anyone                0.127517     0.190476\n",
       "top                   0.228188     0.190476\n",
       "something             0.174497     0.190476\n",
       "finish                0.174497     0.190476\n",
       "one                   0.302013     0.166667\n",
       "cut                   0.087248     0.166667\n",
       "door                  0.187919     0.166667\n",
       "switch                0.046980     0.166667\n",
       "...                        ...          ...\n",
       "guest following       0.006711     0.000000\n",
       "guides week           0.006711     0.000000\n",
       "guest bath            0.000000     0.000000\n",
       "guest                 0.006711     0.000000\n",
       "guessing use          0.000000     0.000000\n",
       "guessing questioning  0.006711     0.000000\n",
       "guessing need         0.000000     0.000000\n",
       "guessing answer       0.000000     0.000000\n",
       "guessing              0.013423     0.000000\n",
       "guides                0.006711     0.000000\n",
       "guitar                0.006711     0.000000\n",
       "guy told              0.000000     0.000000\n",
       "gutters               0.000000     0.000000\n",
       "guy homedepot         0.000000     0.000000\n",
       "guy added             0.006711     0.000000\n",
       "guy                   0.020134     0.000000\n",
       "gutters worked        0.000000     0.000000\n",
       "gutters two           0.000000     0.000000\n",
       "gutters roof          0.000000     0.000000\n",
       "gutters make          0.000000     0.000000\n",
       "gurus built           0.000000     0.000000\n",
       "guitar neck           0.006711     0.000000\n",
       "gurus                 0.000000     0.000000\n",
       "guns beautiful        0.006711     0.000000\n",
       "guns                  0.006711     0.000000\n",
       "gun want              0.000000     0.000000\n",
       "gun standard          0.000000     0.000000\n",
       "gun cleaner           0.006711     0.000000\n",
       "gun                   0.013423     0.000000\n",
       "zoom power            0.000000     0.000000\n",
       "\n",
       "[22178 rows x 2 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "subreddit_1 = 'woodworking'\n",
    "subreddit_2 = 'DIY'\n",
    "m1_df = pd.DataFrame(m1['vector_matrix'].toarray(), columns = m1['features'])\n",
    "m1_df.insert(0, 'subreddit_class', m1['y'])\n",
    "m1_df['subreddit_class'] = m1_df['subreddit_class'].map({1:subreddit_1, 0:subreddit_2})\n",
    "print(\"train score \", m1['train_score'])\n",
    "print(\"test score \", m1['test_score'])\n",
    "\n",
    "\n",
    "\n",
    "m1_df.groupby('subreddit_class').mean().T.sort_values(by = subreddit_1, ascending = False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['title_selftext']\n",
    "y = df['subreddit']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a grid search pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
