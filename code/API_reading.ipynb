{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data from the Reddit API\n",
    "\n",
    "This module runs a script to import reddit posts, stores them in a DataFrame and outputs that DataFrame to a csv file for usage later.  \n",
    "\n",
    "To do this, it employs and a class object and some supporting functions which have been designed to interact with the Reddit HTTP JSON Application Programming Interface (API).  The class object is called ReadReddit and it is built to pull Reddity posts or listings.  It is built using the Requests Python [library](http://docs.python-requests.org/en/master/) for HTTP communication.\n",
    "\n",
    "ReadReddit has the following attributes\n",
    "\n",
    "* url_base - the base URL for data pulls in this case 'http://www.reddit.com/'\n",
    "* url_ - the actual URL used to retrieve data from subreddit\n",
    "* no_posts_ - the number of posts returned after calling collect_posts\n",
    "* status_code_ - the HTTP status code returned after calling collect_posts\n",
    "* json_ = the json format of the web call content\n",
    "* after_ = the after parameter returned from a Reddit API\n",
    "\n",
    "and the following methods\n",
    "    \n",
    "* collect_posts(sub_grp = None, params = {}, headers = {}) - collecting posts data\n",
    "* return_posts() - return the individual posts as a list \n",
    "* return_post_keys() - return the keys of posts records\n",
    "* posts(features = []) - return a list of dictionaries containing posts data\n",
    "    \n",
    "Key functions are hit_reddit and write_data.  Hit_reddit takes inputs of a lists of subreddits and features and repeatedly calls the a variable instantiated as ReadReddit object to retrieve data.  The results are returned as a data frame and saved as a csv file.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### References\n",
    "\n",
    "- https://docs.python.org/3/library/time.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from time import gmtime, strftime, sleep, localtime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to streamline min, max, type and null\n",
    "def print_summary(df):\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            col_type = df[column].dtype\n",
    "        except:\n",
    "            col_type = 'Unknown'\n",
    "        try:\n",
    "            col_min = df[column].min()\n",
    "        except:\n",
    "            col_type = 'Unknown'\n",
    "        try:\n",
    "            col_max = df[column].max()\n",
    "        except:\n",
    "            col_type = 'Unknown'\n",
    "   \n",
    "        print(\"Column: %15s  min: %15s  max: %15s  type: %15s  null: %15s\" % (column[:15], \n",
    "                str(col_min)[:15], str(col_max)[:15], str(col_type)[:15], str(df[column].isnull().sum()))[:15])\n",
    "\n",
    "\n",
    "# Function to hit the reddit API for specified subgroups and features to return\n",
    "def hit_reddit(sub_groups = [], features = [], interval = 30, calls = 15):\n",
    "    \n",
    "    # parameters for the API call\n",
    "    headers = {'user-agent': 'SteveG'}\n",
    "    params = {}\n",
    "    aft_lst = {}\n",
    "    # Calculate the sleep interval\n",
    "    slp_int = min(1, int(interval/calls))\n",
    "    \n",
    "    pst_lst = []\n",
    "    # for each of the calls\n",
    "    for i in range(calls):\n",
    "        # for each subreddit\n",
    "        for j, sub in enumerate(sub_groups):\n",
    "            # If already called pass the after parameter to get latest posts\n",
    "            if i != 0:\n",
    "                params = {'after': aft_lst[j]}\n",
    "            # Call the ReadReddit object to get the posts in a list of dictionaries\n",
    "            posts = ReadReddit()\n",
    "            posts.collect_posts(sub_grp=sub, params = params, headers = headers)\n",
    "            sub_post = posts.posts(features = features)\n",
    "            pst_lst.extend(sub_post)\n",
    "            # Set the after value for the next call to the API\n",
    "            aft_lst[j] = posts.after_\n",
    "        # pause before hitting the API again\n",
    "        time.sleep(slp_int)   \n",
    "    \n",
    "    # Convert the list to a DataFrame and drop dups\n",
    "    df = pd.DataFrame(pst_lst)\n",
    "    df.drop_duplicates(inplace = True)\n",
    "    df.reset_index(drop=True, inplace = True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def write_data(df, data_path):\n",
    "    # assign a unique file name based on the current time\n",
    "    t_stmp = strftime(\"%d%b%Y_%H_%M\", localtime())\n",
    "    o_file = \"posts_\" + t_stmp + \".csv\"\n",
    "    df.to_csv(os.path.join(data_path, o_file), index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadReddit:\n",
    "    # Attributes of the data retrieval\n",
    "    url_base = 'http://www.reddit.com/'\n",
    "    url_ = None\n",
    "    no_posts_ = None\n",
    "    status_code_ = None\n",
    "    json_ = None\n",
    "    after_ = None\n",
    "    \n",
    "    # Initialization method\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    # method to collect data from posts\n",
    "    def collect_posts(self, sub_grp = None, params = {}, headers = {}):\n",
    "        # Set the URL and save it to the class variable\n",
    "        url = self.url_base + 'r/' + sub_grp + '.json'\n",
    "        self.url_ = url\n",
    "        # Hit the API to get posts from this URL\n",
    "        res = requests.get(url, params = params, headers = headers)\n",
    "        # If 200 return\n",
    "        res_code_ = res.status_code\n",
    "        if res.status_code == 200:\n",
    "            self.json_ = res.json()\n",
    "            self.no_posts_ = len(self.json_['data']['children'])\n",
    "            self.after_ = self.json_['data']['after']\n",
    "            return res.json()\n",
    "        else:\n",
    "            return 'Data retrieval error: status code:' + str(res.status_code)\n",
    "\n",
    "    # Method to return the individual posts as a list    \n",
    "    def return_posts(self):\n",
    "        # Refer to the json variable set during collect_posts()\n",
    "        data = self.json_\n",
    "        # Return the children posts\n",
    "        return data['data']['children']\n",
    "    \n",
    "    # Method to return the dictionary keys for posts\n",
    "    def return_post_keys(self):\n",
    "        # Refer to the json variable set during collect_posts()\n",
    "        data = self.json_\n",
    "        # Return the children posts\n",
    "        return data['data']['children'][0]['data'].keys()\n",
    "\n",
    "    # Method to return a list of dictionaries of posts with specified fields\n",
    "    def posts(self, features = []):\n",
    "        # Refer to the json variable set during collect_posts()\n",
    "        data = self.json_\n",
    "        posts = []\n",
    "        # For every entry in the children posts add a dictionary to the list\n",
    "        for entry in data['data']['children']:\n",
    "            post = {}\n",
    "            # For each item in features create a dictionary key: value pair\n",
    "            for item in features:\n",
    "                try:\n",
    "                    post[item] = entry['data'][item]\n",
    "                except:\n",
    "                    post[item] = ''                   \n",
    "            posts.append(post)\n",
    "        return posts\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   Establish parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the parameters for retrieving reddit posts data\n",
    "sub_groups = ['relationships', 'diy','politics', 'woodworking']\n",
    "inc_list = ['name','subreddit','selftext','created_utc','author_fullname',\n",
    "           'title', 'num_comments','id']\n",
    "# Set relative data path\n",
    "data_path = \"../data\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve data from the reddit API and write to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a dataframe of reddit posts\n",
    "df =  hit_reddit(sub_groups = sub_groups, features = inc_list, interval = 300, calls = 150)\n",
    "write_data(df, data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the resulting DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2982, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t2_qu2w0o</td>\n",
       "      <td>1.553775e+09</td>\n",
       "      <td>b6i246</td>\n",
       "      <td>t3_b6i246</td>\n",
       "      <td>641</td>\n",
       "      <td>My husband and I have only been married for 6 ...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>My [28/F] husband [28/M] plays video games non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t2_2ywjm7if</td>\n",
       "      <td>1.553794e+09</td>\n",
       "      <td>b6lpu6</td>\n",
       "      <td>t3_b6lpu6</td>\n",
       "      <td>193</td>\n",
       "      <td>We have been married for a year, together for ...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>My (25F) husband (30M) says there's nothing wr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t2_3hwpjjxa</td>\n",
       "      <td>1.553785e+09</td>\n",
       "      <td>b6jsvh</td>\n",
       "      <td>t3_b6jsvh</td>\n",
       "      <td>244</td>\n",
       "      <td>A little background - I'm 32, have 3 kids with...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>My (32M) girlfriend (29F) keeps using things I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t2_8kmws</td>\n",
       "      <td>1.553753e+09</td>\n",
       "      <td>b6f75y</td>\n",
       "      <td>t3_b6f75y</td>\n",
       "      <td>128</td>\n",
       "      <td>I have a twin brother, which I can honestly sa...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>My (29M) parents (~60MF) seem to favor my twin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t2_3akkhafg</td>\n",
       "      <td>1.553815e+09</td>\n",
       "      <td>b6pw4l</td>\n",
       "      <td>t3_b6pw4l</td>\n",
       "      <td>51</td>\n",
       "      <td>So I noticed my cousin was affectionate and fl...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>I [21M] interfered when my cousin [14F] was ta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  author_fullname   created_utc      id       name  num_comments  \\\n",
       "0       t2_qu2w0o  1.553775e+09  b6i246  t3_b6i246           641   \n",
       "1     t2_2ywjm7if  1.553794e+09  b6lpu6  t3_b6lpu6           193   \n",
       "2     t2_3hwpjjxa  1.553785e+09  b6jsvh  t3_b6jsvh           244   \n",
       "3        t2_8kmws  1.553753e+09  b6f75y  t3_b6f75y           128   \n",
       "4     t2_3akkhafg  1.553815e+09  b6pw4l  t3_b6pw4l            51   \n",
       "\n",
       "                                            selftext      subreddit  \\\n",
       "0  My husband and I have only been married for 6 ...  relationships   \n",
       "1  We have been married for a year, together for ...  relationships   \n",
       "2  A little background - I'm 32, have 3 kids with...  relationships   \n",
       "3  I have a twin brother, which I can honestly sa...  relationships   \n",
       "4  So I noticed my cousin was affectionate and fl...  relationships   \n",
       "\n",
       "                                               title  \n",
       "0  My [28/F] husband [28/M] plays video games non...  \n",
       "1  My (25F) husband (30M) says there's nothing wr...  \n",
       "2  My (32M) girlfriend (29F) keeps using things I...  \n",
       "3  My (29M) parents (~60MF) seem to favor my twin...  \n",
       "4  I [21M] interfered when my cousin [14F] was ta...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the resulting DataFrame\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "politics         1072\n",
       "woodworking       974\n",
       "relationships     610\n",
       "DIY               326\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine Value counts of subreddit\n",
    "df['subreddit'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated rows: 0 \n",
      "\n",
      "Column: author_fullname  min:                  max:      t2_zzoxkw2  type:          object  null:               0\n",
      "Column:     created_utc  min:    1546696172.0  max:    1553823778.0  type:         float64  null:               0\n",
      "Column:              id  min:          acuaez  max:          b6req9  type:          object  null:               0\n",
      "Column:            name  min:       t3_acuaez  max:       t3_b6req9  type:          object  null:               0\n",
      "Column:    num_comments  min:               0  max:            7104  type:           int64  null:               0\n",
      "Column:        selftext  min:                  max: ~~https://m.img  type:          object  null:               0\n",
      "Column:       subreddit  min:             DIY  max:     woodworking  type:          object  null:               0\n",
      "Column:           title  min: \"Still-Secret M  max: “She Was Not In  type:          object  null:               0\n"
     ]
    }
   ],
   "source": [
    "# Count number of duplicated rows\n",
    "print(\"Duplicated rows: %d \\n\" % sum([int(i) for i in df.duplicated()]))\n",
    "\n",
    "#Print a summary of DataFrame columns\n",
    "print_summary(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There might be duplicates in 1955 rows\n"
     ]
    }
   ],
   "source": [
    "# Look for duplicates in the selftext column\n",
    "print(\"There might be duplicates in %d rows\" % (len(df['selftext']) - len(set(df['selftext']))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
